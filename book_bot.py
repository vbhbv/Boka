import os
import logging
import requests
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
import openai

# ๐ ุงููุชุบูุฑุงุช ุงูุจูุฆูุฉ (ูุชู ุฌูุจูุง ูู Railway Secrets)
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# ๐จ ููุงุชูุญ ุงูุจุญุซ ุงูุฐูู
GOOGLE_SEARCH_API_KEY = os.environ.get("GOOGLE_SEARCH_API_KEY")
GOOGLE_SEARCH_CX_ID = os.environ.get("GOOGLE_SEARCH_CX_ID")

# ุฅุนุฏุงุฏ OpenAI
if OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY

# ุฅุนุฏุงุฏุงุช ุงูุชุณุฌูู
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# --- ุซูุงุจุช ูุฅุนุฏุงุฏุงุช ุงููููุงุช ---
MAX_FILE_SIZE = 50 * 1024 * 1024 # 50 ููุฌุงุจุงูุช ูุญุฏ ุฃูุตู ููููุงุช ุงูุจูุช
ALLOWED_CONTENT_TYPE = 'application/pdf'

# ----------------------------------------------------------------------
# ๐ ุฏูุงู ุงูุจุญุซ ูุงูุฌูุจ ุงูุฃุณุงุณูุฉ
# ----------------------------------------------------------------------

# --- ุฏุงูุฉ ุงูุจุญุซ ุงูุฐูู ุนู ุฑุงุจุท ุงูุชุญููู ุจุงุณุชุฎุฏุงู Google Search API ---
def smart_google_search(book_title: str):
    if not GOOGLE_SEARCH_API_KEY or not GOOGLE_SEARCH_CX_ID:
        return None, "ูุฑุฌู ุฅุนุฏุงุฏ ููุงุชูุญ Google Search API ูู ุงููุชุบูุฑุงุช ุงูุจูุฆูุฉ."
    
    # ุงูุจุญุซ ุนู ุงููุชุงุจ ูุน ุชุญุฏูุฏ ููุน ุงูููู PDF
    search_query = f'"{book_title}" filetype:pdf ุชุญููู ูุฌุงูู'
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        'key': GOOGLE_SEARCH_API_KEY,
        'cx': GOOGLE_SEARCH_CX_ID,
        'q': search_query,
        'num': 5  # ุฌูุจ 5 ูุชุงุฆุฌ ูุญุชููุฉ
    }

    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        results = data.get('items', [])
        if not results:
            return None, "ูู ูุชู ุงูุนุซูุฑ ุนูู ุฃู ูุชุงุฆุฌ ุชุญููู ูุจุงุดุฑุฉ (PDF) ูุจุญุซู."

        # ุฅุนุฏุงุฏ ุงูุจูุงูุงุช ูุฅุฑุณุงููุง ุฅูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู
        search_snippets = ""
        for i, item in enumerate(results):
            search_snippets += f"ูุชูุฌุฉ {i+1}: {item.get('title')}\n ุงูุฑุงุจุท: {item.get('link')}\n"

        return results, search_snippets
        
    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู Google Search API: {e}")
        return None, "ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุงูุงุชุตุงู ุจุฎุฏูุฉ ุจุญุซ ุฌูุฌู."

# --- ุฏุงูุฉ ุงุฎุชูุงุฑ ุฃูุถู ุฑุงุจุท ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู ---
def select_best_link_with_ai(book_title: str, snippets: str):
    if not OPENAI_API_KEY:
        return None
    
    prompt = (
        f"ุงููููุฉ: ุฃูุช ุฎุจูุฑ ูู ุชุญุฏูุฏ ุฑูุงุจุท ุชุญููู ุงููุชุจ. ุจูุงุกู ุนูู ูุชุงุฆุฌ ุงูุจุญุซ ุงูุชุงููุฉุ ุงุฎุชุฑ *ุงูุฑุงุจุท ุงููุญูุฏ ุงูุฃูุถู* ุงูุฐู ูู ุงููุฑุฌุญ ุฃู ูุคุฏู ูุจุงุดุฑุฉ ุฅูู ููู PDF ูููุชุงุจ ุจุนููุงู: '{book_title}'.\n"
        f"ุงููุชุทูุจุงุช: ูุฌุจ ุฃู ุชููู ุงูุฅุฌุงุจุฉ ุนุจุงุฑุฉ ุนู ุงูุฑุงุจุท ุงูุตุงูู ููุทุ ุจุฏูู ุฃู ูุต ุฅุถุงูู ุฃู ุดุฑุญ.\n\n"
        f"ูุชุงุฆุฌ ุงูุจุญุซ:\n{snippets}"
    )
    
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ุฃูุช ูุณุงุนุฏ ูุชุฎุตุต ููุฎุชุตุฑ ูููุชู ุงููุญูุฏุฉ ูู ุงุณุชุฎุฑุงุฌ ุฑุงุจุท ูุงุญุฏ ุตุงูู."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.1
        )
        link = response.choices[0].message.content.strip()
        
        if link.startswith("http"):
            return link
        else:
            return None
            
    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู OpenAI API ุฃุซูุงุก ุงูุงุฎุชูุงุฑ: {e}")
        return None
        
# ----------------------------------------------------------------------
# โจ ุฏูุงู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงูุซูุฑูุฉ (ุงูุฑุฏูุฏ / ุงููุญุชูู)
# ----------------------------------------------------------------------

# --- ุฏุงูุฉ ุชูููุฏ ุงููุญุชูู (ูุจุฐุฉ / ุฎุทุฉ ูุฑุงุกุฉ) ุจุงุณุชุฎุฏุงู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ---
def generate_ai_content(book_title: str, mode: str):
    if not OPENAI_API_KEY:
        return f"({mode} ุบูุฑ ูุชููุฑุฉ: ููุชุงุญ OpenAI ุบูุฑ ููุฌูุฏ.)"
    
    if mode == "summary":
        system_role = "ุฃูุช ูุณุงุนุฏ ูุชุฎุตุต ูู ุชูุฎูุต ุงููุชุจ ุจุดูู ููุฌุฒ ูุฌุฐุงุจ."
        user_prompt = f"ุงูุชุจ ูุจุฐุฉ ูููููุฉ ูุฌุฐุงุจุฉ ุนู ูุชุงุจ ุจุนููุงู: '{book_title}'. ูุฌุจ ุฃูุง ุชุชุฌุงูุฒ ุงููุจุฐุฉ 100 ูููุฉ."
        max_tokens = 250
    
    elif mode == "reading_plan":
        system_role = "ุฃูุช ูุฏุฑุจ ูุฑุงุกุฉ ูุชุฎุตุต ูู ุฅูุดุงุก ุฎุทุท ุฒูููุฉ ูุฑูุฉ."
        user_prompt = (
            f"ุฃูุดุฆ ุฎุทุฉ ูุฑุงุกุฉ ูููุธูุฉ ููุญูุฒุฉ ููุฏุฉ 10 ุฃูุงู ููุฑุงุกุฉ ูุชุงุจ ุจุนููุงู: '{book_title}'."
            f"ูุณู ุงููุชุงุจ ุฅูู ุฌูุณุงุช ููููุฉ ูุงุจูุฉ ููุชุทุจูู ูุน ุชุญุฏูุฏ ูุฏู ููู ุฌูุณุฉ (ูุซูุงู: ุงููุตู ุงูุฃูู ูุงูุซุงูู). "
            f"ุงุฌุนู ุชูุณูู ุงูุฅุฎุฑุงุฌ ุณูู ุงููุฑุงุกุฉ ุจุงุณุชุฎุฏุงู ุงูุนูุงููู ูุงูุฃุฑูุงู ูุฑููุฒ ุงูุฅูููุฌู ุงูููุงุณุจุฉ."
        )
        max_tokens = 1024
    else:
        return "ูุถุน ุบูุฑ ูุนุฑูู."

    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_role},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=max_tokens
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู OpenAI API ุฃุซูุงุก ุชูููุฏ {mode}: {e}")
        return f"ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุชูููุฏ {mode} ูููุชุงุจ."

# --- ุฏุงูุฉ ุชูููุฏ ุฑุณุงูุฉ ุงููุดู ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู (ูุฎุตุตุฉ ููููุชุจุงุช ุงูุนุฑุจูุฉ) ---
def generate_failure_response(book_title: str, reason: str):
    if not OPENAI_API_KEY:
        return f"ุนุฐุฑุงูุ ูู ุฃุชููู ูู ุงูุนุซูุฑ ุนูู ุฑุงุจุท ูุจุงุดุฑ ููุชุงุจ '{book_title}'. ุงูุณุจุจ ุงูุชููู: {reason}"
    
    system_role = (
        "ุฃูุช ูุณุงุนุฏ ููุชุจุฉ ุฑููู ูุญุชุฑู ููุจู. ูููุชู ูู ุงูุงุนุชุฐุงุฑ ูููุณุชุฎุฏู ุนู ุนุฏู ุชููุฑ ูุชุงุจุ "
        "ูุชูุฏูู ุชูุณูุฑ ููุฌุฒ ูุฑูุฒ ุนูู ุญููู ุงููุดุฑ ูุชุญุฏูุงุช ุงูุชููุฑ. "
        "ูุฌุจ ุฃู ุชุดูุฑ ูู ุฑุฏู ุฅูู ุฃู ุงููุดููุฉ ูุฏ ุชููู ูุฑุชุจุทุฉ ุจุงููููุฏ ุงูููุฑูุถุฉ ุนูู ุงููุดุฑ ุงูุฑููู ูู ูุจู "
        "ุงูููุชุจุงุช ุงููุจุฑู ุงูุชู ุชูุดุฑ ุงููุชุจ ุงูุนุฑุจูุฉ (ูุซู: ููุชุจุฉ ููุฑุ ููุชุจุฉ ุงููุชูุ ูุชูุจุงุชู). "
        "ูุฌุจ ุฃู ูููู ุงูุฑุฏ ุฏุงูุฆุงู ูููููุงู ูุฃูุง ูุชุฌุงูุฒ ุซูุงุซุฉ ุฌูู."
    )
    user_prompt = (
        f"ุฃุจุญุซ ุนู ูุชุงุจ ุจุนููุงู: '{book_title}'. ูู ูุชููู ุงูุจูุช ูู ุฅูุฌุงุฏู ุฃู ุฅุฑุณุงูู. "
        f"ุงูุณุจุจ ุงูุชููู ุงูุชูุฑูุจู ูู: {reason}"
    )

    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_role},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=200, 
            temperature=0.7 
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู OpenAI API ุฃุซูุงุก ุชูููุฏ ุฑุณุงูุฉ ุงููุดู: {e}")
        return f"ุนุฐุฑุงูุ ูู ุฃุชููู ูู ุงูุนุซูุฑ ุนูู ุฑุงุจุท ูุจุงุดุฑ ููุชุงุจ '{book_title}'. ููุงู ูุดููุฉ ูู ุงูุงุชุตุงู ุจุงูุฎุฏูุงุช ุงูุฐููุฉ."
        
# ----------------------------------------------------------------------
# ๐ค ุฏูุงู ุชููุฌุฑุงู ุงูุฑุฆูุณูุฉ
# ----------------------------------------------------------------------

# --- ุฏุงูุฉ ุฃูุฑ /start ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_message = (
        "ูุฑุญุจุงู ุจู ูู ุจูุช ุงูููุชุจุฉ ุงูุซูุฑูุฉ! ๐\n"
        "ุฃุฑุณู ูู ุงุณู ุงููุชุงุจ ูุณุฃููู ุจูุง ููู:\n"
        "1. ุงูุจุญุซ ุจุฐูุงุก ุนู ุฑุงุจุท ุงูุชุญููู ุงููุจุงุดุฑ.\n"
        "2. ุฅุฑุณุงู ุงูููู (ุฅุฐุง ูุงู ูุณููุญุงู ูุฃูู ูู 50 ููุฌุงุจุงูุช).\n"
        "3. ุฅุฑุณุงู **ูุจุฐุฉ ุฐููุฉ** ู**ุฎุทุฉ ูุฑุงุกุฉ ูุฎุตุตุฉ**."
    )
    await update.message.reply_text(welcome_message, parse_mode='Markdown')


# --- ุฏุงูุฉ ุฅุฑุณุงู ุงูููู ุจุนุฏ ุงูุชุญูู ูุงูุฅุฌุฑุงุกุงุช ุงููุงุญูุฉ ---
async def send_document_if_valid(update: Update, context: ContextTypes.DEFAULT_TYPE, best_link: str, book_title: str):
    
    await update.message.reply_text(f"ุฌุงุฑู ูุญุงููุฉ ุฌูุจ ูุฅุฑุณุงู ููู ุงููุชุงุจ *{book_title}*ุ ุงูุฑุฌุงุก ุงูุงูุชุธุงุฑ ููููุงู...", parse_mode='Markdown')

    try:
        # 1. ูุญุงููุฉ ุฌูุจ ุงูููู
        with requests.get(best_link, stream=True, timeout=30) as r:
            r.raise_for_status()
            
            # ุงูุชุญูู ูู ููุน ุงููุญุชูู ูุญุฌู ุงูููู
            content_type = r.headers.get('Content-Type', '').split(';')[0]
            content_length = int(r.headers.get('Content-Length', 0))

            if ALLOWED_CONTENT_TYPE not in content_type and 'application/octet-stream' not in content_type:
                 await update.message.reply_text(f"โ ูุดู: ุงูุฑุงุจุท ุงููุญุฏุฏ ูุง ูุดูุฑ ูุจุงุดุฑุฉ ุฅูู ููู PDFุ ุจู ูุดูุฑ ุฅูู ุตูุญุฉ ููุจ ุฃู ููุน ููู ุบูุฑ ูุฏุนูู ({content_type}).")
                 return
            
            if content_length > MAX_FILE_SIZE and content_length != 0:
                await update.message.reply_text(f"โ ูุดู: ุญุฌู ุงูููู ุฃูุจุฑ ูู ุงูุญุฏ ุงูุฃูุตู ุงููุณููุญ ุจู (50 ููุฌุงุจุงูุช).")
                return

            # 2. ุฅุฑุณุงู ุงูููู ุนุจุฑ ุชููุฌุฑุงู
            await update.message.reply_document(
                document=r.raw, 
                filename=f"{book_title}.pdf",
                caption=f"โ ุชู ุฅุฑุณุงู ููู *{book_title}* ุจูุงุกู ุนูู ุงูุจุญุซ ุงูุฐูู.",
                parse_mode='Markdown'
            )
            
            # 3. ุงูุฅุถุงูุฉ ุงูุซูุฑูุฉ ุงูุฌุฏูุฏุฉ: ุฅุฑุณุงู ุงููุญุชูู ุงูุฐูู
            
            # ุฃ. ุชูููุฏ ูุฅุฑุณุงู ุงููุจุฐุฉ
            summary_text = generate_ai_content(book_title, "summary")
            await update.message.reply_text(
                f"๐ *ูุจุฐุฉ ุนู ุงููุชุงุจ: {book_title}* ๐\n\n"
                f"{summary_text}",
                parse_mode='Markdown'
            )

            # ุจ. ุชูููุฏ ูุฅุฑุณุงู ุฎุทุฉ ุงููุฑุงุกุฉ
            reading_plan_text = generate_ai_content(book_title, "reading_plan")
            await update.message.reply_text(
                f"๐๏ธ *ุฎุทุฉ ุงููุฑุงุกุฉ ุงูููุชุฑุญุฉ ูู {book_title}* ๐๏ธ\n"
                f"--- (ูุฏุฉ ุงูุฎุทุฉ 10 ุฃูุงู) ---\n\n"
                f"{reading_plan_text}",
                parse_mode='Markdown'
            )
            
    except requests.exceptions.RequestException as e:
        logger.error(f"ุฎุทุฃ ูู ุชุญููู ุงูููู: {e}")
        await update.message.reply_text("โ ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ูุญุงููุฉ ุชุญููู ุงูููู ูู ุงูุฑุงุจุท ุงููุฎุชุงุฑ. ูุฏ ูููู ุงูุฑุงุจุท ุบูุฑ ุตุงูุญ ุฃู ูุญุฌูุจ.")
    except Exception as e:
        logger.error(f"ุฎุทุฃ ุนุงู ุฃุซูุงุก ุงูุฅุฑุณุงู: {e}")
        await update.message.reply_text("โ ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ุบูุฑ ูุชููุน ุฃุซูุงุก ุฅุฑุณุงู ุงูููู.")


# --- ุฏุงูุฉ ูุนุงูุฌุฉ ุงูุฑุณุงุฆู ุงูุฑุฆูุณูุฉ (MessageHandler) ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_query = update.message.text
    
    await update.message.reply_text(f"ุฌุงุฑู ุงูุจุญุซ ุงูุฐูู ุนู ุงููุชุงุจ: *{user_query}*...", parse_mode='Markdown')

    # 1. ุงูุจุญุซ ูู ุฌูุฌู ูุงูุญุตูู ุนูู ุงููุชุงุฆุฌ
    results, search_error = smart_google_search(user_query) 

    if search_error:
        # ุงููุดู ุงูุฃูู: ูุดู ูู ุงูุงุชุตุงู ุจุงูุฎุฏูุงุช
        ai_failure_response = generate_failure_response(user_query, search_error)
        await update.message.reply_text(ai_failure_response, parse_mode='Markdown')
        return

    # 2. ุชุญููู ุงููุชุงุฆุฌ ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุงุฎุชูุงุฑ ุงูุฑุงุจุท ุงูุฃูุถู
    snippets = search_error # ูุฌุจ ุฃู ุชููู search_error ุงูุขู ุชุญูู ุจูุงูุงุช ุงููุชุงุฆุฌ if results is not None
    best_link = select_best_link_with_ai(user_query, snippets)

    if best_link:
        # 3. ูุญุงููุฉ ุฌูุจ ูุฅุฑุณุงู ุงูููู ูุจุงุดุฑุฉ
        await send_document_if_valid(update, context, best_link, user_query)
        
    else:
        # ุงููุดู ุงูุซุงูู: ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู ูุฎุชุฑ ุฑุงุจุทุงู ููุซููุงู
        reason = "ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู ูุชููู ูู ุชุญุฏูุฏ ุฑุงุจุท ุชุญููู PDF ููุซูู ุจู ูู ุจูู ูุชุงุฆุฌ ุงูุจุญุซ."
        ai_failure_response = generate_failure_response(user_query, reason)
        
        # ุฅุฑุณุงู ุงูุฑุฏ ุงููุฎุตุต ูุงูููููุฏ ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู
        await update.message.reply_text(ai_failure_response, parse_mode='Markdown')


# --- ุงูุฏุงูุฉ ุงูุฑุฆูุณูุฉ ูุชุดุบูู ุงูุจูุช ---
def main():
    if not TELEGRAM_BOT_TOKEN:
        logger.error("ูู ูุชู ุงูุนุซูุฑ ุนูู ุฑูุฒ ุงูุชููู (TELEGRAM_BOT_TOKEN). ุงูุฑุฌุงุก ุฅุถุงูุชู ููุชุบูุฑ ุจูุฆู.")
        return

    application = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
    
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message)) 

    logger.info("ุงูุจูุช ูุนูู ุงูุขู ุจูุธุงู ุงูุจุญุซ ุงูุฐูู ุงูุซูุฑู...")
    application.run_polling()

if __name__ == '__main__':
    main()
