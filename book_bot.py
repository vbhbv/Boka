import os
import logging
import requests
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
import openai

# ğŸ” Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© (ÙŠØªÙ… Ø¬Ù„Ø¨Ù‡Ø§ Ù…Ù† Railway Secrets)
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# ğŸš¨ Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ
GOOGLE_SEARCH_API_KEY = os.environ.get("GOOGLE_SEARCH_API_KEY")
GOOGLE_SEARCH_CX_ID = os.environ.get("GOOGLE_SEARCH_CX_ID")

# Ø¥Ø¹Ø¯Ø§Ø¯ OpenAI
if OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Ø«ÙˆØ§Ø¨Øª ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª ---
MAX_FILE_SIZE = 50 * 1024 * 1024 # 50 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙˆØª
ALLOWED_CONTENT_TYPE = 'application/pdf'

# ----------------------------------------------------------------------
# ğŸŒ Ø¯ÙˆØ§Ù„ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# ----------------------------------------------------------------------

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø¹Ù† Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Search API ---
def smart_google_search(book_title: str):
    if not GOOGLE_SEARCH_API_KEY or not GOOGLE_SEARCH_CX_ID:
        return None, "ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØ§ØªÙŠØ­ Google Search API ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©."
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒØªØ§Ø¨ Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù PDF
    search_query = f'"{book_title}" filetype:pdf ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ø§Ù†ÙŠ'
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        'key': GOOGLE_SEARCH_API_KEY,
        'cx': GOOGLE_SEARCH_CX_ID,
        'q': search_query,
        'num': 5  # Ø¬Ù„Ø¨ 5 Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ØªÙ…Ù„Ø©
    }

    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        results = data.get('items', [])
        if not results:
            return None, "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù…ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø±Ø© (PDF) Ù„Ø¨Ø­Ø«Ùƒ."

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        search_snippets = ""
        for i, item in enumerate(results):
            search_snippets += f"Ù†ØªÙŠØ¬Ø© {i+1}: {item.get('title')}\n Ø§Ù„Ø±Ø§Ø¨Ø·: {item.get('link')}\n"

        return results, search_snippets
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Google Search API: {e}")
        return None, "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø¨Ø­Ø« Ø¬ÙˆØ¬Ù„."

# --- Ø¯Ø§Ù„Ø© Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø±Ø§Ø¨Ø· Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ---
def select_best_link_with_ai(book_title: str, snippets: str):
    if not OPENAI_API_KEY:
        return None
    
    prompt = (
        f"Ø§Ù„Ù…Ù‡Ù…Ø©: Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ø±ÙˆØ§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØªØ¨. Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ø§Ø®ØªØ± *Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø£ÙØ¶Ù„* Ø§Ù„Ø°ÙŠ Ù…Ù† Ø§Ù„Ù…Ø±Ø¬Ø­ Ø£Ù† ÙŠØ¤Ø¯ÙŠ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ù…Ù„Ù PDF Ù„Ù„ÙƒØªØ§Ø¨ Ø¨Ø¹Ù†ÙˆØ§Ù†: '{book_title}'.\n"
        f"Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª: ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„ØµØ§ÙÙŠ ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ Ø£Ùˆ Ø´Ø±Ø­.\n\n"
        f"Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«:\n{snippets}"
    )
    
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙˆÙ…Ø®ØªØµØ± Ù…Ù‡Ù…ØªÙƒ Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ù‡ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø§Ø¨Ø· ÙˆØ§Ø­Ø¯ ØµØ§ÙÙŠ."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.1
        )
        link = response.choices[0].message.content.strip()
        
        if link.startswith("http"):
            return link
        else:
            return None
            
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ OpenAI API Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±: {e}")
        return None
        
# ----------------------------------------------------------------------
# âœ¨ Ø¯ÙˆØ§Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠØ© (Ø§Ù„Ø±Ø¯ÙˆØ¯ / Ø§Ù„Ù…Ø­ØªÙˆÙ‰)
# ----------------------------------------------------------------------

# --- Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (Ù†Ø¨Ø°Ø© / Ø®Ø·Ø© Ù‚Ø±Ø§Ø¡Ø©) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ---
def generate_ai_content(book_title: str, mode: str):
    if not OPENAI_API_KEY:
        return f"({mode} ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©: Ù…ÙØªØ§Ø­ OpenAI ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.)"
    
    if mode == "summary":
        system_role = "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ ØªÙ„Ø®ÙŠØµ Ø§Ù„ÙƒØªØ¨ Ø¨Ø´ÙƒÙ„ Ù…ÙˆØ¬Ø² ÙˆØ¬Ø°Ø§Ø¨."
        user_prompt = f"Ø§ÙƒØªØ¨ Ù†Ø¨Ø°Ø© Ù…ÙÙ„Ù‡Ù…Ø© ÙˆØ¬Ø°Ø§Ø¨Ø© Ø¹Ù† ÙƒØªØ§Ø¨ Ø¨Ø¹Ù†ÙˆØ§Ù†: '{book_title}'. ÙŠØ¬Ø¨ Ø£Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² Ø§Ù„Ù†Ø¨Ø°Ø© 100 ÙƒÙ„Ù…Ø©."
        max_tokens = 250
    
    elif mode == "reading_plan":
        system_role = "Ø£Ù†Øª Ù…Ø¯Ø±Ø¨ Ù‚Ø±Ø§Ø¡Ø© Ù…ØªØ®ØµØµ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø·Ø· Ø²Ù…Ù†ÙŠØ© Ù…Ø±Ù†Ø©."
        user_prompt = (
            f"Ø£Ù†Ø´Ø¦ Ø®Ø·Ø© Ù‚Ø±Ø§Ø¡Ø© Ù…ÙÙ†Ø¸Ù…Ø© ÙˆÙ…Ø­ÙØ²Ø© Ù„Ù…Ø¯Ø© 10 Ø£ÙŠØ§Ù… Ù„Ù‚Ø±Ø§Ø¡Ø© ÙƒØªØ§Ø¨ Ø¨Ø¹Ù†ÙˆØ§Ù†: '{book_title}'."
            f"Ù‚Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ø¥Ù„Ù‰ Ø¬Ù„Ø³Ø§Øª ÙŠÙˆÙ…ÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ù‡Ø¯Ù Ù„ÙƒÙ„ Ø¬Ù„Ø³Ø© (Ù…Ø«Ù„Ø§Ù‹: Ø§Ù„ÙØµÙ„ Ø§Ù„Ø£ÙˆÙ„ ÙˆØ§Ù„Ø«Ø§Ù†ÙŠ). "
            f"Ø§Ø¬Ø¹Ù„ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø³Ù‡Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ±Ù…ÙˆØ² Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©."
        )
        max_tokens = 1024
    else:
        return "ÙˆØ¶Ø¹ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ."

    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_role},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=max_tokens
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ OpenAI API Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ {mode}: {e}")
        return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ {mode} Ù„Ù„ÙƒØªØ§Ø¨."

# --- Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ù…Ø®ØµØµØ© Ù„Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©) ---
def generate_failure_response(book_title: str, reason: str):
    if not OPENAI_API_KEY:
        return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø± Ù„ÙƒØªØ§Ø¨ '{book_title}'. Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„ØªÙ‚Ù†ÙŠ: {reason}"
    
    system_role = (
        "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ÙƒØªØ¨Ø© Ø±Ù‚Ù…ÙŠ Ù…Ø­ØªØ±Ù ÙˆÙ„Ø¨Ù‚. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø§Ù„Ø§Ø¹ØªØ°Ø§Ø± Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù† Ø¹Ø¯Ù… ØªÙˆÙØ± ÙƒØªØ§Ø¨ØŒ "
        "ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙØ³ÙŠØ± Ù…ÙˆØ¬Ø² ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù†Ø´Ø± ÙˆØªØ­Ø¯ÙŠØ§Øª Ø§Ù„ØªÙˆÙØ±. "
        "ÙŠØ¬Ø¨ Ø£Ù† ØªØ´ÙŠØ± ÙÙŠ Ø±Ø¯Ùƒ Ø¥Ù„Ù‰ Ø£Ù† Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„Ù…ÙØ±ÙˆØ¶Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø±Ù‚Ù…ÙŠ Ù…Ù† Ù‚Ø¨Ù„ "
        "Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ÙƒØ¨Ø±Ù‰ Ø§Ù„ØªÙŠ ØªÙ†Ø´Ø± Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ù…Ø«Ù„: Ù…ÙƒØªØ¨Ø© Ù†ÙˆØ±ØŒ Ù…ÙƒØªØ¨Ø© Ø§Ù„ÙƒØªÙŠØŒ ÙƒØªÙˆØ¨Ø§ØªÙŠ). "
        "ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø¯ Ø¯Ø§ÙØ¦Ø§Ù‹ ÙˆÙ…Ù‡Ù†ÙŠØ§Ù‹ ÙˆØ£Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² Ø«Ù„Ø§Ø«Ø© Ø¬Ù…Ù„."
    )
    user_prompt = (
        f"Ø£Ø¨Ø­Ø« Ø¹Ù† ÙƒØªØ§Ø¨ Ø¨Ø¹Ù†ÙˆØ§Ù†: '{book_title}'. Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ø¨ÙˆØª Ù…Ù† Ø¥ÙŠØ¬Ø§Ø¯Ù‡ Ø£Ùˆ Ø¥Ø±Ø³Ø§Ù„Ù‡. "
        f"Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„ØªÙ‚Ù†ÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ Ù‡Ùˆ: {reason}"
    )

    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_role},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=200, 
            temperature=0.7 
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ OpenAI API Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„: {e}")
        return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø± Ù„ÙƒØªØ§Ø¨ '{book_title}'. Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø°ÙƒÙŠØ©."
        
# ----------------------------------------------------------------------
# ğŸ¤– Ø¯ÙˆØ§Ù„ ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ----------------------------------------------------------------------

# --- Ø¯Ø§Ù„Ø© Ø£Ù…Ø± /start ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_message = (
        "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø¨ÙˆØª Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø«ÙˆØ±ÙŠØ©! ğŸ“š\n"
        "Ø£Ø±Ø³Ù„ Ù„ÙŠ Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ ÙˆØ³Ø£Ù‚ÙˆÙ… Ø¨Ù…Ø§ ÙŠÙ„ÙŠ:\n"
        "1. Ø§Ù„Ø¨Ø­Ø« Ø¨Ø°ÙƒØ§Ø¡ Ø¹Ù† Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±.\n"
        "2. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø³Ù…ÙˆØ­Ø§Ù‹ ÙˆØ£Ù‚Ù„ Ù…Ù† 50 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª).\n"
        "3. Ø¥Ø±Ø³Ø§Ù„ **Ù†Ø¨Ø°Ø© Ø°ÙƒÙŠØ©** Ùˆ**Ø®Ø·Ø© Ù‚Ø±Ø§Ø¡Ø© Ù…Ø®ØµØµØ©**."
    )
    await update.message.reply_text(welcome_message, parse_mode='Markdown')


# --- Ø¯Ø§Ù„Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù„Ø§Ø­Ù‚Ø© ---
async def send_document_if_valid(update: Update, context: ContextTypes.DEFAULT_TYPE, best_link: str, book_title: str):
    
    await update.message.reply_text(f"Ø¬Ø§Ø±ÙŠ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ ÙˆØ¥Ø±Ø³Ø§Ù„ Ù…Ù„Ù Ø§Ù„ÙƒØªØ§Ø¨ *{book_title}*ØŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹...", parse_mode='Markdown')

    try:
        # 1. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„Ù
        with requests.get(best_link, stream=True, timeout=30) as r:
            r.raise_for_status()
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
            content_type = r.headers.get('Content-Type', '').split(';')[0]
            content_length = int(r.headers.get('Content-Length', 0))

            if ALLOWED_CONTENT_TYPE not in content_type and 'application/octet-stream' not in content_type:
                 await update.message.reply_text(f"âŒ ÙØ´Ù„: Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„Ø§ ÙŠØ´ÙŠØ± Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ù…Ù„Ù PDFØŒ Ø¨Ù„ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ØµÙØ­Ø© ÙˆÙŠØ¨ Ø£Ùˆ Ù†ÙˆØ¹ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… ({content_type}).")
                 return
            
            if content_length > MAX_FILE_SIZE and content_length != 0:
                await update.message.reply_text(f"âŒ ÙØ´Ù„: Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡ (50 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª).")
                return

            # 2. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø¹Ø¨Ø± ØªÙ„ÙŠØ¬Ø±Ø§Ù…
            await update.message.reply_document(
                document=r.raw, 
                filename=f"{book_title}.pdf",
                caption=f"âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ù…Ù„Ù *{book_title}* Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ.",
                parse_mode='Markdown'
            )
            
            # 3. Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒÙŠ
            
            # Ø£. ØªÙˆÙ„ÙŠØ¯ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Ø¨Ø°Ø©
            summary_text = generate_ai_content(book_title, "summary")
            await update.message.reply_text(
                f"ğŸŒŸ *Ù†Ø¨Ø°Ø© Ø¹Ù† Ø§Ù„ÙƒØªØ§Ø¨: {book_title}* ğŸŒŸ\n\n"
                f"{summary_text}",
                parse_mode='Markdown'
            )

            # Ø¨. ØªÙˆÙ„ÙŠØ¯ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø®Ø·Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©
            reading_plan_text = generate_ai_content(book_title, "reading_plan")
            await update.message.reply_text(
                f"ğŸ—“ï¸ *Ø®Ø·Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù„Ù€ {book_title}* ğŸ—“ï¸\n"
                f"--- (Ù…Ø¯Ø© Ø§Ù„Ø®Ø·Ø© 10 Ø£ÙŠØ§Ù…) ---\n\n"
                f"{reading_plan_text}",
                parse_mode='Markdown'
            )
            
    except requests.exceptions.RequestException as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {e}")
        await update.message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø®ØªØ§Ø±. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø§Ø¨Ø· ØºÙŠØ± ØµØ§Ù„Ø­ Ø£Ùˆ Ù…Ø­Ø¬ÙˆØ¨.")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ Ø¹Ø§Ù… Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„: {e}")
        await update.message.reply_text("âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù.")


# --- Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (MessageHandler) ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_query = update.message.text
    
    await update.message.reply_text(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø¹Ù† Ø§Ù„ÙƒØªØ§Ø¨: *{user_query}*...", parse_mode='Markdown')

    # 1. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬ÙˆØ¬Ù„ ÙˆØ§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    results, search_error = smart_google_search(user_query) 

    if search_error:
        # Ø§Ù„ÙØ´Ù„ Ø§Ù„Ø£ÙˆÙ„: ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø¯Ù…Ø§Øª
        ai_failure_response = generate_failure_response(user_query, search_error)
        await update.message.reply_text(ai_failure_response, parse_mode='Markdown')
        return

    # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø£ÙØ¶Ù„
    snippets = search_error # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† search_error Ø§Ù„Ø¢Ù† ØªØ­Ù…Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬ if results is not None
    best_link = select_best_link_with_ai(user_query, snippets)

    if best_link:
        # 3. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø©
        await send_document_if_valid(update, context, best_link, user_query)
        
    else:
        # Ø§Ù„ÙØ´Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù… ÙŠØ®ØªØ± Ø±Ø§Ø¨Ø·Ø§Ù‹ Ù…ÙˆØ«ÙˆÙ‚Ø§Ù‹
        reason = "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ø¯ÙŠØ¯ Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ PDF Ù…ÙˆØ«ÙˆÙ‚ Ø¨Ù‡ Ù…Ù† Ø¨ÙŠÙ† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«."
        ai_failure_response = generate_failure_response(user_query, reason)
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ø®ØµØµ ÙˆØ§Ù„Ù…ÙˆÙ„Ù‘Ø¯ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        await update.message.reply_text(ai_failure_response, parse_mode='Markdown')


# --- Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª ---
def main():
    if not TELEGRAM_BOT_TOKEN:
        logger.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ù…Ø² Ø§Ù„ØªÙˆÙƒÙ† (TELEGRAM_BOT_TOKEN). Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¶Ø§ÙØªÙ‡ ÙƒÙ…ØªØºÙŠØ± Ø¨ÙŠØ¦ÙŠ.")
        return

    application = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
    
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message)) 

    logger.info("Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù† Ø¨Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ...")
    application.run_polling()

if __name__ == '__main__':
    main()
